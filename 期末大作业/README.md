# 期末大作业-微信聊天记录数据分析

## 项目概述

受到年底各大平台的“**年度报告**”启发，于是想利用**Python数据分析与可视化技术**，生成一份基于微信聊天数据的“年度报告”。

本项目通过系统化的数据处理与挖掘，探索了沟通双方的**行为模式、情感动态和核心议题**。

主要包含以下关键模块：

- **基本统计分析**：宏观把握**聊天概况，包括总消息量与成员发言分布**。
- **活跃度分析**：揭示沟通在日、时两个维度上的**时间节律与习惯**。
- **文本内容分析**：通过高频**词云技术**，直观呈现对话的核心话题。
- **情绪动态分析**：利用先进的**自然语言处理模型**，量化并追踪**情感的波动与趋势**。
- **AI综合报告**：借助**大语言模型**，对所有分析结果进行整合，生成一份兼具数据支撑与人文洞察的定性总结。

最终，本项目的核心价值在于将海量的、非结构化的聊天数据，转化为一幅关于沟通模式、互动节律与情感动态的结构化、可解读的洞察图谱。

## 整体分析流程

本项目遵循以下六个核心步骤：

   0.**聊天数据导出**：通过外部工具[echotrace](https://github.com/ycccccccy/echotrace/blob/main/docs/beginner_guide.md)以**json格式**导出需要的微信聊天记录，方便后期数据分析与模型训练训练

1. **环境设置与数据准备**：配置分析所需的编程环境与依赖库，加载原始聊天记录，并进行关键的数据清洗与预处理。
2. **基本统计分析**：计算核心宏观指标，如总消息量和各成员发言数量，建立对聊天概况的初步认知。
3. **活跃度分析**：从时间维度切入，分析每日和每小时的消息分布，以揭示沟通的活跃周期。
4. **文本内容分析**：聚焦于文本信息，通过中文分词与词云可视化，提炼对话中的高频主题词。
5. **情绪分析**：应用深度学习模型对文本进行情感倾向判断，量化并可视化情绪的整体基调与动态变化。
6. **AI聊天分析报告生成**：将前述所有量化分析结果作为输入，利用大型语言模型生成一份综合性的定性分析报告。

接下来详细介绍1-6的数据分析流程，对应代码和结果**见chat_analysis.ipynb文件**

## 1. 环境设置与数据准备

此阶段是所有后续分析的基石。其核心任务是构建一个稳健、高效的分析环境，并对原始数据进行标准化处理，以便于后续的统计与建模。

### **1.1 依赖库与环境配置**

为确保分析的顺利进行，我们首先导入了所有必需的Python库，涵盖了数据处理、可视化、自然语言处理等多个方面。特别地，我们对`Matplotlib`库进行了专门配置，以确保其能够正确渲染中文字符，这对于生成可读性强的中文图表至关重要。

以下是本项目所依赖的核心库：

```python
# -*- coding: utf-8 -*-
import os
import json
import pandas as pd
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
import jieba
from collections import Counter
import re
import requests # 用于AI报告
from pyecharts.charts import Calendar # 用于热力图
from pyecharts import options as opts # 用于热力图

# 设置字体为 'SimHei'
plt.rcParams['font.sans-serif'] = ['SimHei']
# 解决负号'-'显示为方块的问题
plt.rcParams['axes.unicode_minus'] = False

print("\n所有库导入完毕，字体配置完成。")
```

### **1.2 数据加载与预处理**

原始的聊天记录**以JSON格式**存储，为了进行结构化分析，我们设计了`load_and_preprocess_data`函数。该函数的设计思路如下：

1. **健壮的文件加载**：使用`try-except`结构处理潜在的文件未找到（`FileNotFoundError`）或JSON格式错误（`json.JSONDecodeError`）等异常，确保程序的稳定性。
2. **数据帧转换**：将加载的JSON数据高效地转换为`pandas.DataFrame`格式，这是后续所有数据分析的基础。
3. 关键**数据清洗**步骤：
   - **字段重命名**：将原始字段（如`formattedTime`）重命名为更直观的名称（如`time`）。
   - **时间格式转换**：将字符串格式的时间戳转换为标准的日期时间对象，为时间序列分析奠定基础。
   - **时间特征提取**：从日期时间对象中派生出`date`（日期）和`hour`（小时）两个新字段，用于活跃度分析。
   - **消息类型识别**：安全地提取每条消息的`type`，并将其统一为`message_type`字段。

至此，数据准备工作已经完成。我们获得了一个**干净、结构化的数据集**，为接下来的初步数据探索奠定了坚实的基础。

## 2. 基本统计分析

进行**基本统计分析**具有重要的战略意义。它能帮助我们通过宏观数据快速建立对聊天整体情况的认知，例如沟通的规模、参与者的活跃度差异等，为后续更深层次的分析提供关键的上下文基准。

直观地展示两位成员的**参与度差异**，我首先绘制了柱状图来展现成员的发言量情况；同时我也分析了**消息类型的构成**，这有助于**理解双方的沟通习惯和媒介偏好**。

## 3. 活跃度分析

**活跃度分析**通过考察**消息在时间维度上的分布**，旨在揭示沟通参与者的**互动节律、沟通习惯以及潜在的生活作息模式**。这有助于我们理解沟通在何时最为频繁，以及双方的互动是否存在特定的周期性。

### **3.1 每日消息量趋势**

下图展示了在整个观测周期内，每日总消息量的变化趋势。

示例如下：

![image-20260106225417496](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20260106225417496.png)

**图表解读**： 折线图显示，每日的消息量呈现出显著的波动性，不存在平稳的沟通频率。图中存在多个明显的活跃高峰期，单日消息量可超过200条；同时也存在一些相对沉寂的低谷时期。这种波动可能与双方的现实生活事件（如假期、工作繁忙期、共同经历的事件等）密切相关。

### **3.2 每小时聊天活跃度**

为了探究一天之内的沟通模式，我也统计了每个小时的消息总量。

示例如下：

![image-20260106225445233](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20260106225445233.png)

**图表解读**： 该柱状图揭示了清晰的日内沟通节律：

- **凌晨（0-7点）**：沟通基本处于静默状态，符合普遍的作息规律。
- **上午（8-12点）**：从上午8点开始，聊天逐渐变得活跃。
- **下午至傍晚（13-18点）**：活跃度持续攀升，并在**下午16时**左右达到第一个显著高峰。
- **夜晚（19-23点）**：夜晚是沟通的黄金时段，活跃度在**晚上21时**达到全天最高峰，随后逐渐回落。

这种模式典型地反映了学生或上班族在日间的空闲时段及下班/下课后的放松时段进行集中沟通的习惯。

## 4. 文本内容分析：高频词云

本节旨在通过**词云（Word Cloud）技术**，直观地呈现聊天内容中的核心议题和高频词汇。通过**过滤掉无意义的“停用词”**，词云能够快速帮助我们把握对话的焦点，洞察双方最关心的话题。

生成词云的技术流程如下：

1. **加载停用词**：首先，从**外部文件`stop words.txt`中**加载了一个包含**4011个**词的中文停用词表。此举旨在过滤掉如“的”、“了”、“是”等常见但无实际意义的词汇，确保分析的有效性。
2. **提取文本内容**：从数据集中筛选出`message_type`为“文本消息”的记录，并将所有文本内容合并成一个长字符串。
3. **中文分词**：使用**业界流行的`jieba`分词库**对合并后的文本进行分词处理。在分词前，**通过正则表达式移除了所有非中文字符**，以提高分词的准确性。
4. **生成词云**：基于过滤停用词后的词频统计结果，利用`WordCloud`库生成一张可视化图像。在图像中，词语的字体大小与其在聊天中出现的频率成正比。

示例如下：

![image-20260106225310509](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20260106225310509.png)

## 5. 深度情绪分析

情绪分析是本次报告的核心模块之一。它超越了对文本内容的表面理解，旨在量化和洞察对话中蕴含的情感倾向。本节利用了业界前沿的**Hugging Face预训练模型** `uer/roberta-base-finetuned-jd-binary-chinese`，对数据集中全部**7760条**文本消息进行了逐条情感分析，将每条消息归类为**积极、消极或中性**，并以此为基础展开了多维度的**可视化探索**。

### **5.1 整体情绪基调**

首先，我们通过**饼图**来审视两人沟通的整体情绪构成，以建立一个宏观的情绪基调认知。

**示例如下**：

![image-20260106224706837](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20260106224706837.png)

**图表解读**： 根据分析结果，整体的情绪分布呈现出非常积极的态势：

- **积极情绪** 占据主导地位，占比高达 **54.6%**。
- **消极情绪** 占比为 **25.8%**。
- **中性情绪** 占比为 **19.6%**。

这一数据清晰地表明，双方的沟通氛围是健康、积极且富有建设性的。尽管存在一定比例的消极情绪（这在任何真实的长期沟通中都属正常），但积极的情感交流是这段关系的主旋律。

### **5.2 每日情绪“DNA”图谱**

为了更细致地观察情绪随时间的变化以及两位参与者之间的情绪互动，我们绘制了每日情绪热力图，形象地称之为“情绪DNA图谱”。

**示例如下**：

![image-20260106224805134](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20260106224805134.png)

**图表解读**： 该图表以颜色编码每日的平均情绪：**绿色代表积极**，**红色代表消极**，颜色的深浅代表情绪的强度，而坐标轴则分别代表发送者和日期。

- **整体色调**：图谱整体呈现大片的绿色，再次印证了沟通的积极基调。
- **情绪同步性**：在许多天里，两人的情绪色块表现出一致性，表明双方情绪存在一定的同步或相互影响。
- **极端情绪日**：图中也出现了一些深红色或深绿色的“亮点”，这些是情绪波动剧烈的日子，值得我们进一步探究。例如，在9月底和10月初，出现了几个明显的消极（深红）情绪日。

### **5.3 情绪波动曲线对比**

为了更精确地追踪情绪的起伏和关键转折点，还绘制了情绪波动折线图

示例如下：

![image-20260106224905679](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20260106224905679.png)

**图表解读**： 此图清晰地展示了两位成员每日平均情绪分的波动轨迹。

- **情绪峰值**：系统自动标注出了情绪的巅峰时刻，例如“好友”在 **2025年10月28日** 达到了一个情绪高点，而“我”则在 **2025年12月15日** 迎来了自己的开心巅峰。
- **情绪低谷**：同样，最显著的情绪低点也被识别出来，例如“我”在 **2025年09月29日** 经历的情绪低谷，其得分为-0.96。
- **波动趋势**：从整体趋势看，两人的情绪曲线虽各有起伏，但大体上围绕着0分线（中性）上下波动，且多数时间位于0分线以上，与整体积极的基调相符。

## 6. AI 生成的综合分析报告 (Powered by DeepSeek)

利用大型语言模型（DeepSeek）的强大推理与生成能力，将前述所有独立的量化分析结果——包括**基本统计、活跃度模式、高频词汇和情绪动态**——进行整合，生成一份更具洞察力、叙事性和人文关怀的定性分析报告。

- 实现方法：

  构建一个**结构化的Prompt**，其中包含了聊天数据的关键摘要（如时间跨度、消息总数、成员发言分布、核心高频词等），并为AI设定了一个“**精通社会学和心理学的数据分析师**”的专业角色，引导其从更深层次解读数据背后的人际关系与沟通模式。

- 配置方法：

  在`config.py`中把DEEPSEEK_API_KEY字段中填上你在 https://platform.deepseek.com/注册并获取的API key

  ```python
  DEEPSEEK_API_KEY = "你申请的API key"
  ```

> 备注：如果担心聊天记录隐私泄露的话可以不使用此功能

- 示例结果：**见chat_analysis.ipynb的最后一个单元格输出**

## 7. 结论

本项目成功地展示了一套完整的数据科学工作流，将一份原始、非结构化的微信聊天记录，系统性地转化为一个关于沟通行为、时间模式、核心话题和情感动态的深度洞察报告。

此类分析不仅是对技术应用的一次有趣探索，更具有实际的应用价值。它能够帮助个人以一种全新的、数据驱动的视角回顾和理解自己的人际互动，增进对特定关系的认知，甚至可以作为一种独特的数字化日记，记录下那些在日常交流中悄然流逝的情感与时光。